# å°‡ creditcard ä¸­çš„ .json è½‰æ›æˆ credit_rag.jsonl
import json, os
from pathlib import Path

# åŸºæœ¬å·¥å…·ï¼šç”¢ç”Ÿ ID
def make_id(*parts):
    """
    æŠŠå¤šå€‹å­—ä¸²çµ„æˆä¸€å€‹ä¹¾æ·¨çš„ idï¼šå°å¯«ã€åº•ç·šã€ç§»é™¤ç©ºç™½
    """
    cleaned = []
    for p in parts:
        if p is None:
            continue
        s = str(p).strip().replace(" ", "").replace("ï¼š", "_").replace(":", "_")
        cleaned.append(s.lower())
    return "_".join(cleaned)

def detect_reward_type(card_name: str | None = None,
                       family: str | None = None,
                       raw: dict | None = None) -> str:
    text = (card_name or "") + " " + (family or "")
    raw_text = ""
    if raw:
        try:
            import json
            raw_text = json.dumps(raw, ensure_ascii=False)
        except Exception:
            raw_text = str(raw)
    full = text + " " + raw_text

    # 1) äºæ´²è¬é‡Œé€š / é‡Œç¨‹å¡ / miles
    mile_keywords = ["äºæ´²è¬é‡Œé€š", "å“©ç¨‹", "é‡Œæ•¸", "mile", "miles"]
    if any(k in full for k in mile_keywords):
        return "miles"

    # 2) è¦çš®ï¼ˆæ··åˆå›é¥‹ï¼šç¾é‡‘ + è¦å¹£ï¼‰
    shopee_keywords = ["è¦å¹£", "å…é‹"]
    if any(k in full for k in shopee_keywords):
        return "mixed"

    # 3) é»æ•¸ï¼ˆéŠ€è¡Œç´…åˆ©é»æ•¸ã€æ—…éŠç©åˆ†ç­‰ï¼‰
    point_keywords = ["é»", "points", "å°æ¨¹é»"]
    if any(k in full for k in point_keywords):
        return "points"

    return "other"


# è½‰æ› credit_card_profile â†’ chunk
def profile_to_chunk(profile: dict, source_file: str) -> dict:
    card_name = profile.get("card_name", "")
    issuer = profile.get("issuer", "")
    doc_type = profile.get("doc_type", "credit_card_profile")

    # 1. çµ„ textï¼ˆå¯ä»¥è‡ªå·±èª¿æ•´æ¨¡æ¿ï¼Œä¸‹é¢æ˜¯ç°¡å–®ç¤ºç¯„ï¼‰
    annual_fee = profile.get("annual_fee")
    if isinstance(annual_fee, dict):
        annual_fee_str = f"æ­£å¡å¹´è²» {annual_fee.get('primary', '')}ï¼Œé™„å¡{annual_fee.get('supplementary', '')}ã€‚"
        if annual_fee.get("waiver"):
            annual_fee_str += f"å¹´è²»æ¸›å…æ¢ä»¶ï¼š{annual_fee['waiver']}ã€‚"
    else:
        if annual_fee:
            annual_fee_str = f"{annual_fee}ã€‚"
        else:
            annual_fee_str = "å¹´è²»ä¾éŠ€è¡Œå…¬å‘Šã€‚"

    eligibility = profile.get("eligibility") or {}
    income_req = eligibility.get("income_requirement") or profile.get("income_requirement", "")
    age = eligibility.get("age", "")
    employment = eligibility.get("employment", "")

    conds = [age, employment, income_req]
    clean_conds = []
    for c in conds:
        if not c:
            continue
        c = c.rstrip("ã€‚")
        clean_conds.append(c)

    segments = profile.get("target_users") or profile.get("user_segments") or []

    text_parts = [
        f"{issuer}ç™¼è¡Œçš„ã€Œ{card_name}ã€åŸºæœ¬è³‡æ–™ï¼š",
        annual_fee_str,
    ]

    if clean_conds:
        text_parts.append("ç”³è¾¦è³‡æ ¼åŒ…å«ï¼š" + "ã€".join(clean_conds) + "ã€‚")

    if segments:
        text_parts.append("é©åˆæ—ç¾¤ä¾‹å¦‚ï¼š" + "ï¼›".join(segments) + "ã€‚")

    positioning = profile.get("positioning")
    if positioning:
        text_parts.append(f"å¡ç‰‡å®šä½ï¼š{positioning}")

    text = "".join(text_parts)

    family = profile.get("family") or profile.get("card_family")
    reward_type = detect_reward_type(card_name, family, profile)
    
    # å¦‚æœå¡åå«ã€Œè¦çš®ã€ï¼Œå°±ç¡¬æ”¹æˆ mixed
    if "è¦çš®" in card_name:
        reward_type = "mixed"
    # ä¸–ç•Œå¡ï¼šä»¥ç¦®é‡ç‚ºä¸»
    elif "ä¸–ç•Œå¡" in card_name and "äºæ´²è¬é‡Œé€š" not in card_name:
        reward_type = "privilege"

    # 2. çµ„ metadata
    metadata = {
        "card_family": profile.get("family") or profile.get("card_family") or card_name,
        "tier": profile.get("tier"),
        "reward_type": reward_type,
        "main_tags": ["profile"],
        "channel_tags": [],
        "source": profile.get("source"),
        "source_file": source_file,
        "source_path": ["credit_card_profile"],
        "raw": profile
    }

    chunk = {
        "id": make_id(card_name, "profile"),
        "text": text,
        "card_name": card_name,
        "issuer": issuer,
        "doc_type": doc_type,
        "scheme_name": None,
        "rule_type": None,
        "metadata": metadata
    }
    return chunk

# è½‰æ› benefit_scheme â†’ chunks
def scheme_to_chunks(schemes: list[dict], card_name: str, issuer: str, source_file: str) -> list[dict]:
    chunks: list[dict] = []

    for i, s in enumerate(schemes):
        # æœ‰äº› scheme è£¡æœƒè‡ªå·±å¸¶ card_name / card_familyï¼Œç”¨å®ƒå„ªå…ˆï¼Œæ²’æœ‰å†ç”¨åƒæ•¸å¸¶é€²ä¾†çš„ card_name
        scheme_card_name = s.get("card_name") or card_name
        family = s.get("card_family") or scheme_card_name

        scheme_name = s.get("scheme_name", "")
        surface_desc = s.get("surface_desc", "")
        valid_period = s.get("valid_period")

        # ç”¨å…±ç”¨çš„åµæ¸¬å‡½å¼ä¾†æ±ºå®š reward_typeï¼ˆæœƒæŠ“ "äºæ´²è¬é‡Œé€š" / "å“©ç¨‹" ç­‰é—œéµå­—ï¼‰
        reward_type = detect_reward_type(scheme_card_name, family, s)

        # -------- valid_period çµ„äººé¡å¯è®€å­—ä¸²ï¼ˆç‰¹åˆ¥è™•ç† asiamiles é‚£ç¨® dictï¼‰ --------
        valid_period_str = None
        if isinstance(valid_period, dict):
            # å°ˆé–€çµ¦ asiamiles ç”¨çš„äººé¡å¯è®€å­—ä¸²
            gp = valid_period.get("general_spending")
            acc = valid_period.get("accelerator")
            parts = []
            if gp:
                parts.append(f"ä¸€èˆ¬æ¶ˆè²»é‡Œç¨‹ç´¯ç©æœŸé–“ï¼š{gp}")
            if acc:
                parts.append(f"å“©ç¨‹åŠ é€Ÿå™¨æŒ‡å®šé€šè·¯æœŸé–“ï¼š{acc}")
            valid_period_str = "ï¼›".join(parts)
        else:
            valid_period_str = valid_period

        # -------- text --------
        text = f"{scheme_card_name}æ¬Šç›Šæ–¹æ¡ˆã€Œ{scheme_name}ã€ï¼š{surface_desc}"
        if valid_period_str:
            text += f"ï¼ˆé©ç”¨æœŸé–“ï¼š{valid_period_str}ï¼‰"
        elif valid_period:
            # ä¿éšªä¸€å±¤ï¼Œå¦‚æœä¸Šé¢æ²’è½‰å‡ºä¾†å°±ç”¨åŸå§‹çš„
            text += f"ï¼ˆé©ç”¨æœŸé–“ï¼š{valid_period}ï¼‰"

        # âœ… NEWï¼šæŠŠ channel_groups æ”¤å¹³åˆ°æ–‡å­—è£¡ï¼Œè®“ RAG æœå¾—åˆ°é€šè·¯åç¨±
        channel_groups = s.get("channel_groups") or {}
        channels_flat = []
        if isinstance(channel_groups, dict) and channel_groups:
            group_texts = []
            for group_name, shops in channel_groups.items():
                if isinstance(shops, list):
                    shop_list = "ã€".join(shops)
                else:
                    shop_list = str(shops)
                group_texts.append(f"{group_name}ï¼š{shop_list}")
                # é †ä¾¿åšä¸€å€‹æ‰å¹³æ¸…å–®ï¼Œæ”¾åˆ° metadata è®“ä½  debug / éæ¿¾
                if isinstance(shops, list):
                    for shop in shops:
                        channels_flat.append(f"{group_name}-{shop}")
                else:
                    channels_flat.append(f"{group_name}-{shops}")
            text += " æŒ‡å®šé€šè·¯åŒ…å«ï¼š" + "ï¼›".join(group_texts) + "ã€‚"
        else:
            channels_flat = []

        # -------- metadata --------
        metadata = {
            "card_family": family,
            "tier": s.get("tier"),
            "reward_type": reward_type,  # âœ… ç”¨åµæ¸¬å‡ºä¾†çš„ reward_type
            "main_tags": ["benefit_scheme"],
            "channel_tags": [],          # ä¹‹å¾Œå¦‚æœè¦åŠ  channel_tag mapping ä¹Ÿå¯ä»¥åœ¨é€™è£¡æ¥
            "channels_flat": channels_flat,
            "valid_period": valid_period_str or valid_period,
            "source": s.get("source"),
            "source_file": source_file,
            "source_path": ["benefit_scheme", i],
            "raw": s,
        }

        chunk = {
            "id": make_id(scheme_card_name, "scheme", scheme_name or i),
            "text": text,
            "card_name": scheme_card_name,
            "issuer": issuer,
            "doc_type": s.get("doc_type", "benefit_scheme"),
            "scheme_name": scheme_name,
            "rule_type": None,
            "metadata": metadata,
        }
        chunks.append(chunk)

    return chunks

# è½‰æ› benefit_rule â†’ chunksï¼ˆç°¡åŒ–ç‰ˆæ¨¡æ¿ï¼‰
def rule_to_chunks(rules: list, card_name: str, issuer: str, source_file: str) -> list:
    chunks = []
    for i, r in enumerate(rules):
        doc_type = r.get("doc_type", "benefit_rule")
        scheme_id = r.get("scheme_id")
        scheme_name = r.get("scheme_name")  # æœ‰äº›æª”æ¡ˆæ˜¯ç”¨ scheme_name
        rule_type = r.get("rule_type")
        family = r.get("card_family") or card_name
        reward_type = detect_reward_type(card_name, family, r)

        # 1) Shopeeã€Œå›é¥‹åˆ†ç´šã€å°ˆç”¨æ•˜è¿°
        if r.get("rule_type") == "å›é¥‹åˆ†ç´š" and r.get("rules"):
            rules = r["rules"]
            bank = rules.get("bank_provided", {})
            shopee = rules.get("shopee_provided", {})
            special = rules.get("special_period_bonus", {})

            text = (
                f"{card_name}è¦çš®å…¨ç«™å›é¥‹åˆ†ç´šè¦å‰‡ï¼š"
                f"éŠ€è¡Œç«¯ç«™å¤–ä¸€èˆ¬æ¶ˆè²»å›é¥‹ {bank.get('base_reward', '0.5%')}ï¼Œ"
                f"æ–¼è¦çš®å…¨ç«™æ¶ˆè²»å¯ä¾ç•¶æœˆé–€æª»äº« {bank.get('tiered', [{}])[0].get('reward', '1%')} "
                f"æˆ– {bank.get('tiered', [{}, {}])[1].get('reward', '2%')} å›é¥‹ï¼›"
                f"è¦çš®å¹³å°å¦æä¾›éå•†åŸ {shopee.get('non_mall', '1%')}ã€"
                f"å•†åŸ {shopee.get('mall', '2%')} çš„è¦å¹£å›é¥‹ã€‚"
                f"æŒ‡å®šæ´»å‹•æœŸé–“å¦‚è¶…ç´šå“ç‰Œæ—¥èˆ‡ {','.join(special.get('promo_days', []))} ç­‰æª”æœŸï¼Œ"
                f"åˆè¨ˆæœ€é«˜å›é¥‹å¯é” {special.get('max_combined_reward', 'æœ€é«˜ 10%')}ã€‚"
            )

        # 2) ä¸–ç•Œå¡ã€Œé€šç”¨ä½¿ç”¨è¦å‰‡ã€å°ˆç”¨æ•˜è¿°
        if r.get("rule_type") == "é€šç”¨ä½¿ç”¨è¦å‰‡":
            text = (
                f"{card_name}é ‚ç´šç¾é¥Œé€šç”¨ä½¿ç”¨è¦å‰‡ï¼š"
                f"{r.get('usage_limit', '')}"
                f"{'ï¼›' if r.get('usage_limit') else ''}"
                f"{r.get('service_charge', '')}"
                f"ï¼›{r.get('reservation', '')}"
                f"ï¼›{r.get('blackout', '')}"
                f"ï¼›{r.get('stacking', '')}"
                f"ï¼›{r.get('note', '')}"
            )



        channel_group = r.get("channel_group")

        # 1. ç²—æš´åšæ³•ï¼šæŠŠé‡è¦æ¬„ä½ä¸²æˆæ–‡å­—ï¼ˆä½ å¯ä»¥æ…¢æ…¢å„ªåŒ–ï¼‰
        text_parts = [f"{card_name}"]
        if scheme_name:
            text_parts.append(f"ã€Œ{scheme_name}ã€")
        elif scheme_id:
            text_parts.append(f"ï¼ˆæ–¹æ¡ˆIDï¼š{scheme_id}ï¼‰")
        if rule_type:
            text_parts.append(f"{rule_type}ï¼š")

        # å˜—è©¦æŠŠå¸¸è¦‹æ¬„ä½åŠ å…¥æ–‡å­—
        for key in ["include", "exclude", "conditions", "benefits",
                    "lounges", "sharing_rule", "how_to_use", "offers"]:
            val = r.get(key)
            if val:
                if isinstance(val, list):
                    text_parts.append(f"{key} åŒ…å«ï¼š" + "ï¼›".join(map(str, val)) + "ã€‚")
                else:
                    text_parts.append(f"{key}ï¼š{val}ã€‚")

        # å¦‚æœæœ‰ tiers / restaurants / rules é€™ç¨®è¤‡é›œçµæ§‹ï¼Œå¯ä»¥å…ˆç°¡å–®æè¿°
        if r.get("tiers"):
            text_parts.append("æ­¤è¦å‰‡ä¾ä¸åŒå¡åˆ¥æœ‰åˆ†ç´šå·®ç•°ã€‚")
        if r.get("restaurants"):
            text_parts.append("æ­¤è¦å‰‡é©ç”¨æ–¼å¤šå®¶æŒ‡å®šé¤å»³ã€‚")
        if r.get("rules"):
            text_parts.append("è©³ç´°å›é¥‹èˆ‡é–€æª»ä¾è¤‡é›œåˆ†ç´šè¦å‰‡è¨ˆç®—ã€‚")

        text = "".join(text_parts)

        metadata = {
            "card_family": r.get("card_family") or card_name,
            "tier": None,
            "reward_type": reward_type,
            "main_tags": ["benefit_rule"],
            # "channel_tags": [],
            "channel_tags": map_channel_tag(channel_group),
            "valid_period": r.get("valid_period"),
            "source": r.get("source"),
            "source_file": source_file,
            "source_path": ["benefit_rule", i],
            "raw": r
        }

        chunk = {
            "id": make_id(card_name, "rule", scheme_name or scheme_id, f"idx{i}"),
            "text": text,
            "card_name": card_name,
            "issuer": issuer,
            "doc_type": doc_type,
            "scheme_name": scheme_name,
            "rule_type": rule_type,
            "metadata": metadata
        }
        chunks.append(chunk)
    return chunks

# channel_group è‡ªå‹•å¡« channel_tags
def map_channel_tag(channel_group: str | None) -> list[str]:
    if not channel_group:
        return []
    mapping = {
        # ç©æ•¸ä½
        "æ•¸ä½ä¸²æµå¹³å°": ["digital", "entertainment"],
        "AIå·¥å…·": ["digital", "software"],
        "ç¶²è³¼å¹³å°": ["online_shopping"],
        "åœ‹éš›é›»å•†": ["online_shopping", "overseas"],

        # æ¨‚é¥—è³¼
        "åœ‹å…§æŒ‡å®šç™¾è²¨": ["department_store", "shopping_mall"],
        "åœ‹å…§é¤é£²": ["dining"],
        "åœ‹å…§å¤–é€å¹³å°": ["dining", "delivery"],
        "åœ‹å…§è—¥å¦": ["drugstore", "beauty"],

        # è¶£æ—…è¡Œ
        "æŒ‡å®šæµ·å¤–æ¶ˆè²»": ["overseas", "travel", "shopping"],
        "æ—¥æœ¬æŒ‡å®šéŠæ¨‚åœ’": ["travel", "entertainment", "theme_park"],
        "æŒ‡å®šåœ‹å…§å¤–äº¤é€š": ["transportation", "travel"],
        "æŒ‡å®šèˆªç©ºå…¬å¸": ["airline", "travel"],
        "æŒ‡å®šé£¯åº—ä½å®¿": ["hotel", "travel"],
        "æŒ‡å®šæ—…éŠ/è¨‚æˆ¿å¹³å°": ["travel", "online_booking"],
        "æŒ‡å®šæ—…è¡Œç¤¾": ["travel_agency", "travel"],

        # é›†ç²¾é¸
        "é‡è²©è¶…å¸‚": ["grocery", "hypermarket"],
        "æŒ‡å®šåŠ æ²¹": ["gas"],
        "æŒ‡å®šè¶…å•†": ["convenience_store"],
        "ç”Ÿæ´»å®¶å±…": ["home", "furniture", "lifestyle"],

        # è¦çš®è¯åå¡
        "è¦çš®è³¼ç‰©": ["online_shopping", "platform"]
    }
    return mapping.get(channel_group, [])

def global_rule_to_chunks(global_rules, card_name: str, issuer: str, source_file: str) -> list[dict]:
    """
    å°‡ global_rule å€å¡Šè½‰æˆ chunk
    æœƒæŠŠåƒã€Œæ¬Šç›Šæ–¹æ¡ˆåˆ‡æ›èˆ‡ç”Ÿæ•ˆæ—¥ã€ã€Œæ¬Šç›Šé©ç”¨æœŸé–“èˆ‡æ–¹æ¡ˆåˆ‡æ›ã€é€™ç¨®è¦å‰‡å¯«æˆä¸€æ®µæ–‡å­—ï¼Œ
    è®“ RAG å¯ä»¥æŠ“åˆ°ã€Œä¸€å¤©æœ€å¤šåˆ‡æ›ä¸€æ¬¡ã€ã€ã€Œç•¶æ—¥é›¶æ™‚èµ·ç”Ÿæ•ˆã€é€™é¡è³‡è¨Šã€‚
    """
    chunks: list[dict] = []

    # æœ‰äº›æª”æ¡ˆï¼ˆåƒ cube_structured.jsonï¼‰è£¡çš„ global_rule æœƒæœ‰ã€Œlist è£¡é¢åˆåŒ… listã€ï¼Œ
    # é€™è£¡å…ˆæ”¤å¹³æˆå–®ä¸€ list
    flat_rules: list[dict] = []
    if isinstance(global_rules, dict):
        flat_rules = [global_rules]
    elif isinstance(global_rules, list):
        for item in global_rules:
            if isinstance(item, list):
                flat_rules.extend(item)
            else:
                flat_rules.append(item)

    for i, r in enumerate(flat_rules):
        if not isinstance(r, dict):
            continue

        doc_type = r.get("doc_type", "global_rule")
        rule_name = r.get("rule_name", "")
        rule_text = r.get("rule_text", "")
        valid_period = r.get("valid_period")
        conditions = r.get("conditions") or {}
        note = r.get("note")

        # ---- çµ„æ–‡å­— ----
        # ä¸»å¹¹ï¼šå¡å + è¦å‰‡åç¨± + è¦å‰‡èªªæ˜
        text_parts = []
        if card_name:
            text_parts.append(f"{card_name}")
        if rule_name:
            text_parts.append(f"ã€Œ{rule_name}ã€ï¼š")
        text_parts.append(rule_text)

        # æŠŠ conditions æ”¤æˆäººé¡å¥½è®€çš„ä¸€å°æ®µ
        # ä¾‹å¦‚ï¼š
        # - æ¯ä½æ­£å¡æŒå¡äººæ¯æ—¥æœ€å¤šå¯è®Šæ›´æ–¹æ¡ˆ1æ¬¡
        # - è®Šæ›´ç•¶æ—¥é›¶æ™‚èµ·ä¹‹æ¶ˆè²»ä¾æ–°æ–¹æ¡ˆè¨ˆç®—å›é¥‹
        if isinstance(conditions, dict) and conditions:
            cond_lines = []
            for k, v in conditions.items():
                cond_lines.append(f"{v}")
            if cond_lines:
                text_parts.append(" æ¢ä»¶åŒ…å«ï¼š" + "ï¼›".join(cond_lines) + "ã€‚")

        # æœ‰æ•ˆæœŸé–“
        if valid_period:
            text_parts.append(f"ï¼ˆé©ç”¨æœŸé–“ï¼š{valid_period}ï¼‰")

        if note:
            text_parts.append(f" å‚™è¨»ï¼š{note}")

        text = "".join(text_parts)

        metadata = {
            "card_family": card_name,
            "tier": None,
            "reward_type": "other",
            "main_tags": ["global_rule"],
            "channel_tags": [],
            "valid_period": valid_period,
            "source": r.get("source"),
            "source_file": source_file,
            "source_path": ["global_rule", i],
            "raw": r,
        }

        chunk = {
            "id": make_id(card_name, "global_rule", rule_name or f"idx{i}"),
            "text": text,
            "card_name": card_name,
            "issuer": issuer,
            "doc_type": doc_type,
            "scheme_name": None,
            "rule_type": None,
            "metadata": metadata,
        }
        chunks.append(chunk)

    return chunks


# welcome_offer â†’ chunks
def welcome_to_chunks(welcome, card_name: str, issuer: str, source_file: str) -> list:
    """
    welcome å¯èƒ½æ˜¯ dictï¼ˆè¦çš®ã€ä¸–ç•Œå¡ï¼‰ä¹Ÿå¯èƒ½æ˜¯ listï¼ˆäºæ´²è¬é‡Œé€šï¼‰
    çµ±ä¸€è½‰æˆ list è™•ç†
    """
    chunks = []
    if isinstance(welcome, dict):
        welcome_list = [welcome]
    else:
        welcome_list = welcome

    for i, w in enumerate(welcome_list):
        offer_name = w.get("offer_name", "æ–°æˆ¶ç¦®")
        period = w.get("valid_period")
        conditions = w.get("conditions") or w.get("requirements") or []
        reward = w.get("reward")
        channel_group = w.get("channel_group")

        text_parts = [
            f"{card_name} {offer_name}ï¼š",
        ]
        if conditions:
            text_parts.append("é”æˆæ¢ä»¶ï¼š" + "ï¼›".join(conditions) + "ã€‚")
        if isinstance(reward, dict):
            text_parts.append("å›é¥‹å…§å®¹ï¼š" + "ã€".join([f"{k}: {v}" for k, v in reward.items()]) + "ã€‚")
        elif reward:
            text_parts.append(f"å›é¥‹å…§å®¹ï¼š{reward}ã€‚")
        if period:
            text_parts.append(f"æ´»å‹•æœŸé–“ï¼š{period}ã€‚")

        text = "".join(text_parts)

        metadata = {
            "card_family": w.get("family"),
            "tier": None,
            "reward_type": "mixed",
            "main_tags": ["welcome_offer"],
            "channel_tags": map_channel_tag(channel_group),
            "valid_period": period,
            "source": w.get("source"),
            "source_file": source_file,
            "source_path": ["welcome_offer", i],
            "raw": w
        }

        chunk = {
            "id": make_id(card_name, "welcome", i),
            "text": text,
            "card_name": card_name,
            "issuer": issuer,
            "doc_type": "welcome_offer",
            "scheme_name": None,
            "rule_type": None,
            "metadata": metadata
        }
        chunks.append(chunk)
    return chunks

# æŠŠ 4 ä»½ JSON æª”å„è‡ªè½‰æˆ chunk list
def convert_file(path: str) -> list:
    path_obj = Path(path)
    with open(path_obj, "r", encoding="utf-8") as f:
        data = json.load(f)

    source_file = path_obj.name
    chunks = []

    # æƒ…æ³ä¸€ï¼šåƒ shopee.json / worldcard_structured.jsonï¼ˆæœ€å¤–å±¤æœ‰ card_nameï¼‰
    if isinstance(data, dict) and "card_name" in data:
        card_name = data.get("card_name")
        issuer = data.get("issuer", "åœ‹æ³°ä¸–è¯éŠ€è¡Œ")

        profile = data.get("credit_card_profile")
        if isinstance(profile, dict):
            chunks.append(profile_to_chunk(profile, source_file))
        elif isinstance(profile, list):
            for p in profile:
                chunks.append(profile_to_chunk(p, source_file))

        if "benefit_scheme" in data:
            chunks += scheme_to_chunks(data["benefit_scheme"], card_name, issuer, source_file)

        if "benefit_rule" in data:
            chunks += rule_to_chunks(data["benefit_rule"], card_name, issuer, source_file)

        if "welcome_offer" in data:  # shopee / worldcard æ˜¯ welcome_offerï¼ˆå–®æ•¸ï¼‰
            chunks += welcome_to_chunks(data["welcome_offer"], card_name, issuer, source_file)

                # ğŸ”¹ æ–°å¢ï¼šè™•ç† global_ruleï¼ˆåƒ CUBE çš„åˆ‡æ›è¦å‰‡ã€æ¬Šç›Šåˆ†ç´šç­‰ï¼‰
        if "global_rule" in data:
            chunks += global_rule_to_chunks(data["global_rule"], card_name=card_name, issuer=issuer, source_file=source_file)


    # æƒ…æ³äºŒï¼šåƒ colab.jsonï¼ˆæœ€å¤–å±¤æœ‰ card_family + å¤šå¼µ cardï¼‰
    elif isinstance(data, dict) and "credit_card_profile" in data and "card_family" in data:
        issuer = data.get("issuer", "åœ‹æ³°ä¸–è¯éŠ€è¡Œ")
        card_family = data.get("card_family")

        for p in data["credit_card_profile"]:
            chunks.append(profile_to_chunk(p, source_file))

        if "benefit_scheme" in data:
            chunks += scheme_to_chunks(
                data["benefit_scheme"],
                card_name=card_family,
                issuer=issuer,
                source_file=source_file
            )

        if "benefit_rule" in data:
            chunks += rule_to_chunks(
                data["benefit_rule"],
                card_name=card_family,
                issuer=issuer,
                source_file=source_file
            )

        if "welcome_offer" in data:
            for w in data["welcome_offer"]:
                chunks += welcome_to_chunks(
                    welcome=w,
                    card_name=w.get("card_name", card_family),
                    issuer=issuer,
                    source_file=source_file
                )

        if "global_rule" in data:
            chunks += global_rule_to_chunks(
                data["global_rule"],
                card_name=card_family,
                issuer=issuer,
                source_file=source_file
            )

    # âœ… æƒ…æ³ä¸‰ï¼šåƒ cube_structured.jsonï¼ˆæœ‰ credit_card_profileï¼Œä½†æ²’æœ‰ card_name / card_familyï¼‰
    elif isinstance(data, dict) and "credit_card_profile" in data:
        profiles = data.get("credit_card_profile") or []
        # CUBE çš„ profile æ˜¯ list
        if isinstance(profiles, list) and profiles:
            # ç”¨ç¬¬ä¸€å€‹ profile ç•¶å…±ç”¨ card_name / issuer
            first = profiles[0]
            card_name = first.get("card_name", path_obj.stem)
            issuer = first.get("issuer", "åœ‹æ³°ä¸–è¯éŠ€è¡Œ")

            for p in profiles:
                chunks.append(profile_to_chunk(p, source_file))

            if "benefit_scheme" in data:
                chunks += scheme_to_chunks(data["benefit_scheme"], card_name, issuer, source_file)

            if "benefit_rule" in data:
                chunks += rule_to_chunks(data["benefit_rule"], card_name, issuer, source_file)

            # âš  cube_structured.json çš„ key å« welcome_offersï¼ˆè¤‡æ•¸ï¼‰
            if "welcome_offers" in data:
                chunks += welcome_to_chunks(data["welcome_offers"], card_name, issuer, source_file)

            if "global_rule" in data:
                chunks += global_rule_to_chunks(data["global_rule"], card_name=card_name, issuer=issuer, source_file=source_file)

    return chunks


# å¯«æˆ JSONL æª”æ¡ˆ
def main():
    base_dir = "creditcard_json"
    
    input_files = [
        "cube_structured.json",
        "shopee.json",
        "worldcard_structured.json",
        "colab.json"
    ]
    input_paths = [os.path.join(base_dir, f) for f in input_files]

    all_chunks = []
    for path in input_paths:
        file_chunks = convert_file(path)
        print(path, "ç”¢ç”Ÿ chunk æ•¸é‡ï¼š", len(file_chunks))
        all_chunks.extend(file_chunks)

    print("ç¸½å…± chunk æ•¸é‡ï¼š", len(all_chunks))
    
    output_path = os.path.join(os.path.dirname(base_dir), "cards_rag.jsonl")
    
    with open(output_path, "w", encoding="utf-8") as f:
        for chunk in all_chunks:
            f.write(json.dumps(chunk, ensure_ascii=False) + "\n")


if __name__ == "__main__":
    main()


